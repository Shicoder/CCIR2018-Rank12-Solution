2017-11-24 13:28:36,794 - INFO - rnn_size: 64  batch_size:64  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.0005
2017-11-24 13:29:41,462 - INFO - Epoch: 0 loss: 0.988189 Recall@20: 0.03457627118644068 MRR@20: 0.013048704838624551
2017-11-24 13:34:12,909 - INFO - Epoch: 5 loss: 0.933195 Recall@20: 0.13152542372881357 MRR@20: 0.046198746001626836
2017-11-24 13:38:44,130 - INFO - Epoch: 10 loss: 0.911212 Recall@20: 0.18101694915254238 MRR@20: 0.06308889878727732
2017-11-24 13:43:16,687 - INFO - Epoch: 15 loss: 0.898626 Recall@20: 0.21491525423728813 MRR@20: 0.07324312703441106
2017-11-24 13:47:49,325 - INFO - Epoch: 20 loss: 0.890146 Recall@20: 0.2454237288135593 MRR@20: 0.08651661984211703
2017-11-24 13:52:23,624 - INFO - Epoch: 25 loss: 0.883966 Recall@20: 0.26305084745762713 MRR@20: 0.09137309845180969
2017-11-24 13:56:57,283 - INFO - Epoch: 30 loss: 0.879127 Recall@20: 0.2698305084745763 MRR@20: 0.0921770142977311
2017-11-24 14:01:15,688 - INFO - Epoch: 35 loss: 0.875294 Recall@20: 0.28135593220338984 MRR@20: 0.09256804233122645
2017-11-24 14:05:44,035 - INFO - Epoch: 40 loss: 0.872133 Recall@20: 0.28135593220338984 MRR@20: 0.09312185961118112
2017-11-24 14:10:11,383 - INFO - Epoch: 45 loss: 0.869455 Recall@20: 0.2901694915254237 MRR@20: 0.09395697553977979
2017-11-24 14:13:48,910 - INFO - rnn_size: 64  batch_size:64  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.001
2017-11-24 14:14:52,737 - INFO - Epoch: 0 loss: 0.980992 Recall@20: 0.04677966101694915 MRR@20: 0.017358453152964356
2017-11-24 14:19:22,358 - INFO - Epoch: 5 loss: 0.910459 Recall@20: 0.16745762711864406 MRR@20: 0.05913422995526685
2017-11-24 14:23:51,843 - INFO - Epoch: 10 loss: 0.890371 Recall@20: 0.2359322033898305 MRR@20: 0.08430564632815772
2017-11-24 14:28:21,979 - INFO - Epoch: 15 loss: 0.879634 Recall@20: 0.26305084745762713 MRR@20: 0.09126273718992928
2017-11-24 14:32:50,518 - INFO - Epoch: 20 loss: 0.872676 Recall@20: 0.28203389830508474 MRR@20: 0.09643347159973598
2017-11-24 14:37:20,087 - INFO - Epoch: 25 loss: 0.867779 Recall@20: 0.2928813559322034 MRR@20: 0.1005005905337542
2017-11-24 14:41:49,263 - INFO - Epoch: 30 loss: 0.864157 Recall@20: 0.29694915254237286 MRR@20: 0.10069416019195628
2017-11-24 14:46:18,354 - INFO - Epoch: 35 loss: 0.861429 Recall@20: 0.3152542372881356 MRR@20: 0.10595502024110932
2017-11-24 14:50:34,715 - INFO - Epoch: 40 loss: 0.859213 Recall@20: 0.31796610169491524 MRR@20: 0.10252773112680234
2017-11-24 14:55:02,525 - INFO - Epoch: 45 loss: 0.857422 Recall@20: 0.3159322033898305 MRR@20: 0.10404792113660245
2017-11-24 14:58:41,779 - INFO - rnn_size: 64  batch_size:64  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.005
2017-11-24 14:59:45,776 - INFO - Epoch: 0 loss: 0.947705 Recall@20: 0.10779661016949152 MRR@20: 0.03662946044818848
2017-11-24 15:04:18,727 - INFO - Epoch: 5 loss: 0.872700 Recall@20: 0.31186440677966104 MRR@20: 0.10982278016829623
2017-11-24 15:08:53,984 - INFO - Epoch: 10 loss: 0.861156 Recall@20: 0.3376271186440678 MRR@20: 0.11169182733447833
2017-11-24 15:13:32,115 - INFO - Epoch: 15 loss: 0.856390 Recall@20: 0.328135593220339 MRR@20: 0.09816671943787966
2017-11-24 15:18:07,974 - INFO - Epoch: 20 loss: 0.853949 Recall@20: 0.32677966101694916 MRR@20: 0.10425047069330008
2017-11-24 15:22:41,045 - INFO - Epoch: 25 loss: 0.852545 Recall@20: 0.3159322033898305 MRR@20: 0.09355005386537106
2017-11-24 15:27:15,035 - INFO - Epoch: 30 loss: 0.851688 Recall@20: 0.30915254237288137 MRR@20: 0.09116157566582607
2017-11-24 15:31:50,449 - INFO - Epoch: 35 loss: 0.851116 Recall@20: 0.31796610169491524 MRR@20: 0.09548346080872185
2017-11-24 15:35:51,033 - INFO - Epoch: 40 loss: 0.850663 Recall@20: 0.30915254237288137 MRR@20: 0.09431725423305944
2017-11-24 15:39:59,663 - INFO - Epoch: 45 loss: 0.850350 Recall@20: 0.3213559322033898 MRR@20: 0.09140198272863431
2017-11-24 15:43:21,456 - INFO - rnn_size: 64  batch_size:64  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.005
2017-11-24 15:44:06,477 - INFO - Epoch: 0 loss: 0.991085 Recall@20: 0.04610169491525424 MRR@20: 0.01734483209327099
2017-11-24 15:47:09,321 - INFO - Epoch: 5 loss: 0.947672 Recall@20: 0.13898305084745763 MRR@20: 0.04106179542239783
2017-11-24 15:50:10,829 - INFO - Epoch: 10 loss: 0.929247 Recall@20: 0.20135593220338982 MRR@20: 0.06596548038669045
2017-11-24 15:53:13,161 - INFO - Epoch: 15 loss: 0.918530 Recall@20: 0.23254237288135593 MRR@20: 0.07739805325655667
2017-11-24 15:56:15,848 - INFO - Epoch: 20 loss: 0.911092 Recall@20: 0.2488135593220339 MRR@20: 0.08330505300731463
2017-11-24 15:59:05,352 - INFO - Epoch: 25 loss: 0.905387 Recall@20: 0.2576271186440678 MRR@20: 0.08668034493303424
2017-11-24 16:02:04,883 - INFO - Epoch: 30 loss: 0.900715 Recall@20: 0.2684745762711864 MRR@20: 0.08693903070336925
2017-11-24 16:05:02,702 - INFO - Epoch: 35 loss: 0.896889 Recall@20: 0.2738983050847458 MRR@20: 0.08989388491028306
2017-11-24 16:08:01,103 - INFO - Epoch: 40 loss: 0.893624 Recall@20: 0.2874576271186441 MRR@20: 0.09324982954927333
2017-11-24 16:10:59,742 - INFO - Epoch: 45 loss: 0.890710 Recall@20: 0.29627118644067796 MRR@20: 0.09642695862439264
2017-11-24 16:13:26,934 - INFO - rnn_size: 64  batch_size:64  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.01
2017-11-24 16:14:11,710 - INFO - Epoch: 0 loss: 0.983351 Recall@20: 0.03796610169491525 MRR@20: 0.010288446224034197
2017-11-24 16:17:08,299 - INFO - Epoch: 5 loss: 0.917889 Recall@20: 0.2223728813559322 MRR@20: 0.07124653214352539
2017-11-24 16:20:05,986 - INFO - Epoch: 10 loss: 0.899582 Recall@20: 0.2664406779661017 MRR@20: 0.08633814001907092
2017-11-24 16:23:02,720 - INFO - Epoch: 15 loss: 0.889236 Recall@20: 0.29559322033898305 MRR@20: 0.09015735313877728
2017-11-24 16:25:52,974 - INFO - Epoch: 20 loss: 0.882390 Recall@20: 0.3023728813559322 MRR@20: 0.09368833179495924
2017-11-24 16:28:57,909 - INFO - Epoch: 25 loss: 0.877499 Recall@20: 0.31186440677966104 MRR@20: 0.0958873793118428
2017-11-24 16:32:01,381 - INFO - Epoch: 30 loss: 0.873785 Recall@20: 0.3213559322033898 MRR@20: 0.09871193261328119
2017-11-24 16:35:03,062 - INFO - Epoch: 35 loss: 0.870871 Recall@20: 0.3220338983050847 MRR@20: 0.09997306842696986
2017-11-24 16:38:07,878 - INFO - Epoch: 40 loss: 0.868526 Recall@20: 0.3240677966101695 MRR@20: 0.1018518274213819
2017-11-24 16:41:10,506 - INFO - Epoch: 45 loss: 0.866574 Recall@20: 0.32949152542372884 MRR@20: 0.10417295250154567
2017-11-24 16:43:39,269 - INFO - rnn_size: 64  batch_size:64  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.05
2017-11-24 16:44:23,649 - INFO - Epoch: 0 loss: 0.927916 Recall@20: 0.22508474576271187 MRR@20: 0.07842954353139586
2017-11-24 16:47:21,237 - INFO - Epoch: 5 loss: 0.860941 Recall@20: 0.34711864406779663 MRR@20: 0.12233161602060165
2017-11-24 16:50:09,869 - INFO - Epoch: 10 loss: 0.853902 Recall@20: 0.34915254237288135 MRR@20: 0.11729826477709147
2017-11-24 16:53:06,223 - INFO - Epoch: 15 loss: 0.851110 Recall@20: 0.34508474576271186 MRR@20: 0.10676185637664357
2017-11-24 16:56:04,878 - INFO - Epoch: 20 loss: 0.849571 Recall@20: 0.3423728813559322 MRR@20: 0.10744969941464666
2017-11-24 16:59:02,212 - INFO - Epoch: 25 loss: 0.848621 Recall@20: 0.33152542372881355 MRR@20: 0.10707236714472898
2017-11-24 17:01:59,542 - INFO - Epoch: 30 loss: 0.848049 Recall@20: 0.3389830508474576 MRR@20: 0.10692933729846672
2017-11-24 17:04:55,924 - INFO - Epoch: 35 loss: 0.847531 Recall@20: 0.3369491525423729 MRR@20: 0.1029493524147982
2017-11-24 17:07:53,749 - INFO - Epoch: 40 loss: 0.847151 Recall@20: 0.33016949152542374 MRR@20: 0.10354472408644105
2017-11-24 17:10:52,139 - INFO - Epoch: 45 loss: 0.846776 Recall@20: 0.33559322033898303 MRR@20: 0.101995381534501
2017-11-24 17:13:19,599 - INFO - rnn_size: 64  batch_size:128  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.0005
2017-11-24 17:13:56,422 - INFO - Epoch: 0 loss: 0.992074 Recall@20: 0.04203389830508475 MRR@20: 0.015064611608270105
2017-11-24 17:16:13,153 - INFO - Epoch: 5 loss: 0.935539 Recall@20: 0.12677966101694915 MRR@20: 0.0484316902334691
2017-11-24 17:18:19,857 - INFO - Epoch: 10 loss: 0.913795 Recall@20: 0.18237288135593221 MRR@20: 0.06299250686635899
2017-11-24 17:20:34,785 - INFO - Epoch: 15 loss: 0.901421 Recall@20: 0.22372881355932203 MRR@20: 0.07865576029271784
2017-11-24 17:22:50,506 - INFO - Epoch: 20 loss: 0.892960 Recall@20: 0.25152542372881354 MRR@20: 0.0935623307473284
2017-11-24 17:25:06,636 - INFO - Epoch: 25 loss: 0.886663 Recall@20: 0.25966101694915256 MRR@20: 0.09452031235339206
2017-11-24 17:27:22,559 - INFO - Epoch: 30 loss: 0.881866 Recall@20: 0.2738983050847458 MRR@20: 0.0938561800242285
2017-11-24 17:29:38,767 - INFO - Epoch: 35 loss: 0.878049 Recall@20: 0.28271186440677964 MRR@20: 0.09576740150114763
2017-11-24 17:31:55,016 - INFO - Epoch: 40 loss: 0.874881 Recall@20: 0.29084745762711867 MRR@20: 0.09590164116899698
2017-11-24 17:34:10,290 - INFO - Epoch: 45 loss: 0.872252 Recall@20: 0.29694915254237286 MRR@20: 0.09706457084745902
2017-11-24 17:36:03,881 - INFO - rnn_size: 64  batch_size:128  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.001
2017-11-24 17:36:41,680 - INFO - Epoch: 0 loss: 0.984816 Recall@20: 0.04745762711864407 MRR@20: 0.014672325721074212
2017-11-24 17:39:00,420 - INFO - Epoch: 5 loss: 0.913453 Recall@20: 0.16677966101694916 MRR@20: 0.0618634790314488
2017-11-24 17:41:17,416 - INFO - Epoch: 10 loss: 0.893379 Recall@20: 0.2366101694915254 MRR@20: 0.08502808292615188
2017-11-24 17:43:20,667 - INFO - Epoch: 15 loss: 0.882631 Recall@20: 0.26237288135593223 MRR@20: 0.0947112800325793
2017-11-24 17:45:10,402 - INFO - Epoch: 20 loss: 0.875747 Recall@20: 0.28203389830508474 MRR@20: 0.09567042659520487
2017-11-24 17:47:00,555 - INFO - Epoch: 25 loss: 0.870757 Recall@20: 0.29627118644067796 MRR@20: 0.09884545642157017
2017-11-24 17:48:50,769 - INFO - Epoch: 30 loss: 0.867221 Recall@20: 0.30101694915254235 MRR@20: 0.10460226342605519
2017-11-24 17:50:41,480 - INFO - Epoch: 35 loss: 0.864478 Recall@20: 0.3159322033898305 MRR@20: 0.10376850337980109
2017-11-24 17:52:31,717 - INFO - Epoch: 40 loss: 0.862300 Recall@20: 0.3159322033898305 MRR@20: 0.10039255777834777
2017-11-24 17:54:22,015 - INFO - Epoch: 45 loss: 0.860554 Recall@20: 0.3206779661016949 MRR@20: 0.09885410410897107
2017-11-24 17:55:54,812 - INFO - rnn_size: 64  batch_size:128  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.005
2017-11-24 17:56:26,615 - INFO - Epoch: 0 loss: 0.950764 Recall@20: 0.13491525423728815 MRR@20: 0.04411152644269084
2017-11-24 17:58:16,794 - INFO - Epoch: 5 loss: 0.875956 Recall@20: 0.29559322033898305 MRR@20: 0.10045228664276781
2017-11-24 18:00:07,233 - INFO - Epoch: 10 loss: 0.864499 Recall@20: 0.328135593220339 MRR@20: 0.10792862379497214
2017-11-24 18:01:49,948 - INFO - Epoch: 15 loss: 0.859739 Recall@20: 0.31457627118644066 MRR@20: 0.10257082052007803
2017-11-24 18:03:39,051 - INFO - Epoch: 20 loss: 0.857484 Recall@20: 0.3111864406779661 MRR@20: 0.09552066608652114
2017-11-24 18:05:28,893 - INFO - Epoch: 25 loss: 0.855995 Recall@20: 0.3064406779661017 MRR@20: 0.09753060689288848
2017-11-24 18:07:18,160 - INFO - Epoch: 30 loss: 0.855099 Recall@20: 0.29694915254237286 MRR@20: 0.10003135721973944
2017-11-24 18:09:07,796 - INFO - Epoch: 35 loss: 0.854453 Recall@20: 0.3105084745762712 MRR@20: 0.09794737890831189
2017-11-24 18:10:57,907 - INFO - Epoch: 40 loss: 0.853999 Recall@20: 0.3105084745762712 MRR@20: 0.09238180132182335
2017-11-24 18:12:48,266 - INFO - Epoch: 45 loss: 0.853629 Recall@20: 0.3016949152542373 MRR@20: 0.09440170633503792
2017-11-24 18:14:20,587 - INFO - rnn_size: 64  batch_size:128  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.005
2017-11-24 18:14:47,416 - INFO - Epoch: 0 loss: 0.995710 Recall@20: 0.01966101694915254 MRR@20: 0.012720062036113878
2017-11-24 18:16:14,937 - INFO - Epoch: 5 loss: 0.963713 Recall@20: 0.10711864406779661 MRR@20: 0.035571274742760284
2017-11-24 18:17:41,561 - INFO - Epoch: 10 loss: 0.941319 Recall@20: 0.17559322033898306 MRR@20: 0.05636828902849262
2017-11-24 18:19:01,154 - INFO - Epoch: 15 loss: 0.928738 Recall@20: 0.21898305084745762 MRR@20: 0.07499165153877332
2017-11-24 18:20:27,029 - INFO - Epoch: 20 loss: 0.920130 Recall@20: 0.23864406779661018 MRR@20: 0.08460874005857477
2017-11-24 18:21:52,361 - INFO - Epoch: 25 loss: 0.913628 Recall@20: 0.25152542372881354 MRR@20: 0.08685300177599595
2017-11-24 18:23:17,960 - INFO - Epoch: 30 loss: 0.908469 Recall@20: 0.26372881355932204 MRR@20: 0.08985300999455904
2017-11-24 18:24:43,912 - INFO - Epoch: 35 loss: 0.904120 Recall@20: 0.27796610169491526 MRR@20: 0.09447065811055422
2017-11-24 18:26:10,396 - INFO - Epoch: 40 loss: 0.900500 Recall@20: 0.28677966101694913 MRR@20: 0.09433794760218123
2017-11-24 18:27:35,903 - INFO - Epoch: 45 loss: 0.897305 Recall@20: 0.29084745762711867 MRR@20: 0.09658739076540934
2017-11-24 18:28:48,893 - INFO - rnn_size: 64  batch_size:128  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.01
2017-11-24 18:29:15,387 - INFO - Epoch: 0 loss: 0.993713 Recall@20: 0.04745762711864407 MRR@20: 0.016449258769193703
2017-11-24 18:30:42,259 - INFO - Epoch: 5 loss: 0.928823 Recall@20: 0.2040677966101695 MRR@20: 0.07045040628387954
2017-11-24 18:32:08,339 - INFO - Epoch: 10 loss: 0.907929 Recall@20: 0.26033898305084746 MRR@20: 0.08640323186867763
2017-11-24 18:33:34,517 - INFO - Epoch: 15 loss: 0.896424 Recall@20: 0.2888135593220339 MRR@20: 0.09526803377425196
2017-11-24 18:35:00,516 - INFO - Epoch: 20 loss: 0.888821 Recall@20: 0.29694915254237286 MRR@20: 0.09845341403041986
2017-11-24 18:36:20,713 - INFO - Epoch: 25 loss: 0.883361 Recall@20: 0.3016949152542373 MRR@20: 0.10203037235804725
2017-11-24 18:37:44,795 - INFO - Epoch: 30 loss: 0.879229 Recall@20: 0.3105084745762712 MRR@20: 0.10387613635832141
2017-11-24 18:39:09,052 - INFO - Epoch: 35 loss: 0.875937 Recall@20: 0.31864406779661014 MRR@20: 0.10395808550011727
2017-11-24 18:40:33,593 - INFO - Epoch: 40 loss: 0.873383 Recall@20: 0.32610169491525426 MRR@20: 0.10437760979349371
2017-11-24 18:41:58,828 - INFO - Epoch: 45 loss: 0.871148 Recall@20: 0.33220338983050846 MRR@20: 0.105406844599897
2017-11-24 18:43:10,811 - INFO - rnn_size: 64  batch_size:128  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.05
2017-11-24 18:43:37,300 - INFO - Epoch: 0 loss: 0.943032 Recall@20: 0.1871186440677966 MRR@20: 0.06304937992572457
2017-11-24 18:45:03,176 - INFO - Epoch: 5 loss: 0.867678 Recall@20: 0.328135593220339 MRR@20: 0.11332385482550777
2017-11-24 18:46:29,838 - INFO - Epoch: 10 loss: 0.858500 Recall@20: 0.3464406779661017 MRR@20: 0.1164164029809724
2017-11-24 18:47:55,570 - INFO - Epoch: 15 loss: 0.854927 Recall@20: 0.34508474576271186 MRR@20: 0.11457392264903937
2017-11-24 18:49:21,786 - INFO - Epoch: 20 loss: 0.853116 Recall@20: 0.3403389830508475 MRR@20: 0.10999064289217514
2017-11-24 18:50:47,192 - INFO - Epoch: 25 loss: 0.851989 Recall@20: 0.3396610169491525 MRR@20: 0.11038385566553693
2017-11-24 18:52:13,263 - INFO - Epoch: 30 loss: 0.851275 Recall@20: 0.3396610169491525 MRR@20: 0.11270216725954774
2017-11-24 18:53:39,398 - INFO - Epoch: 35 loss: 0.850678 Recall@20: 0.33559322033898303 MRR@20: 0.11292094032966155
2017-11-24 18:54:59,152 - INFO - Epoch: 40 loss: 0.850239 Recall@20: 0.3328813559322034 MRR@20: 0.11081216985191901
2017-11-24 18:56:25,036 - INFO - Epoch: 45 loss: 0.849849 Recall@20: 0.3288135593220339 MRR@20: 0.1078168158184425
2017-11-24 18:57:39,003 - INFO - rnn_size: 64  batch_size:256  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.0005
2017-11-24 18:58:01,765 - INFO - Epoch: 0 loss: 0.994367 Recall@20: 0.04542372881355932 MRR@20: 0.01677983012946543
2017-11-24 18:59:07,392 - INFO - Epoch: 5 loss: 0.936648 Recall@20: 0.1423728813559322 MRR@20: 0.045907374455493255
2017-11-24 19:00:13,777 - INFO - Epoch: 10 loss: 0.915115 Recall@20: 0.18372881355932202 MRR@20: 0.06417497644065309
2017-11-24 19:01:21,329 - INFO - Epoch: 15 loss: 0.902845 Recall@20: 0.2216949152542373 MRR@20: 0.08156824370640815
2017-11-24 19:02:29,181 - INFO - Epoch: 20 loss: 0.894471 Recall@20: 0.24203389830508473 MRR@20: 0.08948122191720342
2017-11-24 19:03:37,103 - INFO - Epoch: 25 loss: 0.888312 Recall@20: 0.25898305084745765 MRR@20: 0.09379824711387919
2017-11-24 19:04:44,423 - INFO - Epoch: 30 loss: 0.883509 Recall@20: 0.2705084745762712 MRR@20: 0.09415069884608634
2017-11-24 19:05:52,119 - INFO - Epoch: 35 loss: 0.879753 Recall@20: 0.28067796610169493 MRR@20: 0.09401709298904555
2017-11-24 19:07:00,849 - INFO - Epoch: 40 loss: 0.876637 Recall@20: 0.2847457627118644 MRR@20: 0.09334388174255413
2017-11-24 19:08:08,293 - INFO - Epoch: 45 loss: 0.874016 Recall@20: 0.29084745762711867 MRR@20: 0.09429015851884091
2017-11-24 19:09:06,336 - INFO - rnn_size: 64  batch_size:256  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.001
2017-11-24 19:09:30,252 - INFO - Epoch: 0 loss: 0.987446 Recall@20: 0.04745762711864407 MRR@20: 0.013598079094064821
2017-11-24 19:10:38,854 - INFO - Epoch: 5 loss: 0.915314 Recall@20: 0.16610169491525423 MRR@20: 0.06278575316807987
2017-11-24 19:11:41,292 - INFO - Epoch: 10 loss: 0.895299 Recall@20: 0.23457627118644067 MRR@20: 0.08786303756180969
2017-11-24 19:13:23,758 - INFO - Epoch: 15 loss: 0.884477 Recall@20: 0.26576271186440675 MRR@20: 0.09507174424929055
2017-11-24 19:15:06,028 - INFO - Epoch: 20 loss: 0.877540 Recall@20: 0.2847457627118644 MRR@20: 0.09751416215101476
2017-11-24 19:16:47,409 - INFO - Epoch: 25 loss: 0.872754 Recall@20: 0.3016949152542373 MRR@20: 0.1026506647544849
2017-11-24 19:18:28,986 - INFO - Epoch: 30 loss: 0.869170 Recall@20: 0.3044067796610169 MRR@20: 0.1068729481790824
2017-11-24 19:20:09,555 - INFO - Epoch: 35 loss: 0.866350 Recall@20: 0.30915254237288137 MRR@20: 0.1060124962756542
2017-11-24 19:21:50,996 - INFO - Epoch: 40 loss: 0.864235 Recall@20: 0.3057627118644068 MRR@20: 0.10427832521795369
2017-11-24 19:23:31,152 - INFO - Epoch: 45 loss: 0.862431 Recall@20: 0.30983050847457627 MRR@20: 0.10614302861726381
2017-11-24 19:24:56,242 - INFO - rnn_size: 64  batch_size:256  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.005
2017-11-24 19:25:26,649 - INFO - Epoch: 0 loss: 0.953637 Recall@20: 0.12677966101694915 MRR@20: 0.04109926152453833
2017-11-24 19:27:08,136 - INFO - Epoch: 5 loss: 0.878285 Recall@20: 0.2976271186440678 MRR@20: 0.10006115256010306
2017-11-24 19:28:50,352 - INFO - Epoch: 10 loss: 0.866845 Recall@20: 0.3254237288135593 MRR@20: 0.10967715443850198
2017-11-24 19:30:30,313 - INFO - Epoch: 15 loss: 0.862270 Recall@20: 0.31661016949152543 MRR@20: 0.09823894000270136
2017-11-24 19:32:10,542 - INFO - Epoch: 20 loss: 0.859750 Recall@20: 0.3213559322033898 MRR@20: 0.0954886505342506
2017-11-24 19:33:52,685 - INFO - Epoch: 25 loss: 0.858327 Recall@20: 0.3220338983050847 MRR@20: 0.09868906519541457
2017-11-24 19:35:35,121 - INFO - Epoch: 30 loss: 0.857426 Recall@20: 0.31864406779661014 MRR@20: 0.0998084442188446
2017-11-24 19:37:17,429 - INFO - Epoch: 35 loss: 0.856884 Recall@20: 0.3105084745762712 MRR@20: 0.1017326587023024
2017-11-24 19:38:59,388 - INFO - Epoch: 40 loss: 0.856323 Recall@20: 0.32745762711864407 MRR@20: 0.10031789581393405
2017-11-24 19:40:41,370 - INFO - Epoch: 45 loss: 0.855998 Recall@20: 0.31322033898305085 MRR@20: 0.09815213870513759
2017-11-24 19:42:07,133 - INFO - rnn_size: 64  batch_size:256  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.005
2017-11-24 19:42:31,617 - INFO - Epoch: 0 loss: 0.997920 Recall@20: 0.008135593220338983 MRR@20: 0.005030559835644581
2017-11-24 19:43:49,856 - INFO - Epoch: 5 loss: 0.984873 Recall@20: 0.06033898305084746 MRR@20: 0.020525047069912473
2017-11-24 19:45:08,535 - INFO - Epoch: 10 loss: 0.959453 Recall@20: 0.0976271186440678 MRR@20: 0.036149551980847565
2017-11-24 19:46:27,613 - INFO - Epoch: 15 loss: 0.943859 Recall@20: 0.14847457627118643 MRR@20: 0.05273747577336809
2017-11-24 19:47:45,862 - INFO - Epoch: 20 loss: 0.933369 Recall@20: 0.18033898305084745 MRR@20: 0.06479687613116275
2017-11-24 19:49:04,203 - INFO - Epoch: 25 loss: 0.925629 Recall@20: 0.20813559322033898 MRR@20: 0.07560975837115838
2017-11-24 19:50:22,825 - INFO - Epoch: 30 loss: 0.919581 Recall@20: 0.23389830508474577 MRR@20: 0.08666501950586539
2017-11-24 19:51:41,732 - INFO - Epoch: 35 loss: 0.914559 Recall@20: 0.24745762711864408 MRR@20: 0.0894853674862333
2017-11-24 19:52:59,710 - INFO - Epoch: 40 loss: 0.910349 Recall@20: 0.26169491525423727 MRR@20: 0.09250629614739915
2017-11-24 19:54:18,193 - INFO - Epoch: 45 loss: 0.906710 Recall@20: 0.2738983050847458 MRR@20: 0.093025074771887
2017-11-24 19:55:25,509 - INFO - rnn_size: 64  batch_size:256  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.01
2017-11-24 19:55:50,590 - INFO - Epoch: 0 loss: 0.997536 Recall@20: 0.02440677966101695 MRR@20: 0.009696287911536901
2017-11-24 19:57:10,193 - INFO - Epoch: 5 loss: 0.949368 Recall@20: 0.13898305084745763 MRR@20: 0.045898655401725136
2017-11-24 19:58:29,682 - INFO - Epoch: 10 loss: 0.922728 Recall@20: 0.2094915254237288 MRR@20: 0.07922831967086046
2017-11-24 19:59:49,581 - INFO - Epoch: 15 loss: 0.908702 Recall@20: 0.25152542372881354 MRR@20: 0.08914332231585735
2017-11-24 20:01:08,801 - INFO - Epoch: 20 loss: 0.899458 Recall@20: 0.27728813559322035 MRR@20: 0.09293696141946128
2017-11-24 20:02:28,741 - INFO - Epoch: 25 loss: 0.892733 Recall@20: 0.2847457627118644 MRR@20: 0.09737140116126841
2017-11-24 20:03:47,906 - INFO - Epoch: 30 loss: 0.887695 Recall@20: 0.2935593220338983 MRR@20: 0.10225130884985534
2017-11-24 20:05:07,420 - INFO - Epoch: 35 loss: 0.883711 Recall@20: 0.30033898305084744 MRR@20: 0.10247976109237066
2017-11-24 20:06:26,454 - INFO - Epoch: 40 loss: 0.880408 Recall@20: 0.31254237288135595 MRR@20: 0.10457497353881884
2017-11-24 20:07:46,277 - INFO - Epoch: 45 loss: 0.877748 Recall@20: 0.31728813559322033 MRR@20: 0.10467071450119672
2017-11-24 20:08:53,094 - INFO - rnn_size: 64  batch_size:256  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.05
2017-11-24 20:09:08,639 - INFO - Epoch: 0 loss: 0.963898 Recall@20: 0.11254237288135593 MRR@20: 0.03385979428150284
2017-11-24 20:10:28,182 - INFO - Epoch: 5 loss: 0.878052 Recall@20: 0.31254237288135595 MRR@20: 0.10248849103238569
2017-11-24 20:11:48,891 - INFO - Epoch: 10 loss: 0.864832 Recall@20: 0.3328813559322034 MRR@20: 0.11150937391481548
2017-11-24 20:13:08,702 - INFO - Epoch: 15 loss: 0.859360 Recall@20: 0.3383050847457627 MRR@20: 0.11190866571348808
2017-11-24 20:14:30,124 - INFO - Epoch: 20 loss: 0.856573 Recall@20: 0.33559322033898303 MRR@20: 0.10928604878589138
2017-11-24 20:15:50,552 - INFO - Epoch: 25 loss: 0.854838 Recall@20: 0.3328813559322034 MRR@20: 0.11217517554422628
2017-11-24 20:17:10,464 - INFO - Epoch: 30 loss: 0.853750 Recall@20: 0.3328813559322034 MRR@20: 0.10979333585551772
2017-11-24 20:18:30,504 - INFO - Epoch: 35 loss: 0.852920 Recall@20: 0.33220338983050846 MRR@20: 0.10899252950672379
2017-11-24 20:19:49,621 - INFO - Epoch: 40 loss: 0.852428 Recall@20: 0.32610169491525426 MRR@20: 0.10609920126866652
2017-11-24 20:21:09,690 - INFO - Epoch: 45 loss: 0.851916 Recall@20: 0.3227118644067797 MRR@20: 0.10223647373773312
2017-11-24 20:22:17,814 - INFO - rnn_size:128  batch_size:64  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.0005
2017-11-24 20:23:36,162 - INFO - Epoch: 0 loss: 0.986349 Recall@20: 0.04745762711864407 MRR@20: 0.017936888800797076
2017-11-24 20:29:19,658 - INFO - Epoch: 5 loss: 0.920361 Recall@20: 0.151864406779661 MRR@20: 0.054377295822250434
2017-11-24 20:35:04,564 - INFO - Epoch: 10 loss: 0.896720 Recall@20: 0.2135593220338983 MRR@20: 0.07467687146597783
2017-11-24 20:40:47,647 - INFO - Epoch: 15 loss: 0.883459 Recall@20: 0.2454237288135593 MRR@20: 0.08706470528882242
2017-11-24 20:46:28,434 - INFO - Epoch: 20 loss: 0.874465 Recall@20: 0.26576271186440675 MRR@20: 0.09736712516987482
2017-11-24 20:52:11,712 - INFO - Epoch: 25 loss: 0.867938 Recall@20: 0.2854237288135593 MRR@20: 0.10157963049643268
2017-11-24 20:57:56,990 - INFO - Epoch: 30 loss: 0.862908 Recall@20: 0.29559322033898305 MRR@20: 0.1050067929947764
2017-11-24 21:03:35,998 - INFO - Epoch: 35 loss: 0.858795 Recall@20: 0.3030508474576271 MRR@20: 0.10649072012686432
2017-11-24 21:08:57,004 - INFO - Epoch: 40 loss: 0.855471 Recall@20: 0.31457627118644066 MRR@20: 0.10927131970546462
2017-11-24 21:14:30,482 - INFO - Epoch: 45 loss: 0.852692 Recall@20: 0.3220338983050847 MRR@20: 0.1147261971672424
2017-11-24 21:19:01,102 - INFO - rnn_size:128  batch_size:64  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.001
2017-11-24 21:20:18,473 - INFO - Epoch: 0 loss: 0.976414 Recall@20: 0.06576271186440678 MRR@20: 0.02412377530231862
2017-11-24 21:25:53,209 - INFO - Epoch: 5 loss: 0.897097 Recall@20: 0.20813559322033898 MRR@20: 0.07107413242626025
2017-11-24 21:31:28,899 - INFO - Epoch: 10 loss: 0.875462 Recall@20: 0.26372881355932204 MRR@20: 0.09912076136418897
2017-11-24 21:37:03,753 - INFO - Epoch: 15 loss: 0.863975 Recall@20: 0.29627118644067796 MRR@20: 0.10884998418290646
2017-11-24 21:42:39,328 - INFO - Epoch: 20 loss: 0.856529 Recall@20: 0.3111864406779661 MRR@20: 0.11545751763585103
2017-11-24 21:48:12,983 - INFO - Epoch: 25 loss: 0.851275 Recall@20: 0.33084745762711865 MRR@20: 0.11926448549264312
2017-11-24 21:53:48,113 - INFO - Epoch: 30 loss: 0.847455 Recall@20: 0.3335593220338983 MRR@20: 0.12335224491390205
2017-11-24 21:59:23,700 - INFO - Epoch: 35 loss: 0.844419 Recall@20: 0.3376271186440678 MRR@20: 0.1267029362485363
2017-11-24 22:04:44,558 - INFO - Epoch: 40 loss: 0.842049 Recall@20: 0.3464406779661017 MRR@20: 0.12521515799447794
2017-11-24 22:10:22,284 - INFO - Epoch: 45 loss: 0.840327 Recall@20: 0.34779661016949154 MRR@20: 0.12442850584898128
2017-11-24 22:14:55,629 - INFO - rnn_size:128  batch_size:64  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.005
2017-11-24 22:16:13,204 - INFO - Epoch: 0 loss: 0.939956 Recall@20: 0.16542372881355932 MRR@20: 0.05569328494411141
2017-11-24 22:21:50,590 - INFO - Epoch: 5 loss: 0.859234 Recall@20: 0.3389830508474576 MRR@20: 0.12075256749279421
2017-11-24 22:27:27,069 - INFO - Epoch: 10 loss: 0.846767 Recall@20: 0.3566101694915254 MRR@20: 0.12286866177906214
2017-11-24 22:33:04,979 - INFO - Epoch: 15 loss: 0.842162 Recall@20: 0.3559322033898305 MRR@20: 0.1219305737670118
2017-11-24 22:38:39,723 - INFO - Epoch: 20 loss: 0.839903 Recall@20: 0.34983050847457625 MRR@20: 0.11815868032313435
2017-11-24 22:44:16,734 - INFO - Epoch: 25 loss: 0.838542 Recall@20: 0.3430508474576271 MRR@20: 0.11032683612528292
2017-11-24 22:49:52,759 - INFO - Epoch: 30 loss: 0.837727 Recall@20: 0.3389830508474576 MRR@20: 0.11211056313215623
2017-11-24 22:55:29,838 - INFO - Epoch: 35 loss: 0.837127 Recall@20: 0.33152542372881355 MRR@20: 0.11152340552114913
2017-11-24 23:00:50,254 - INFO - Epoch: 40 loss: 0.836651 Recall@20: 0.34440677966101696 MRR@20: 0.10942355736536352
2017-11-24 23:06:26,460 - INFO - Epoch: 45 loss: 0.836435 Recall@20: 0.3369491525423729 MRR@20: 0.11582406780919138
2017-11-24 23:10:59,115 - INFO - rnn_size:128  batch_size:64  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.005
2017-11-24 23:11:58,069 - INFO - Epoch: 0 loss: 0.990464 Recall@20: 0.061016949152542375 MRR@20: 0.019987184079905913
2017-11-24 23:16:05,200 - INFO - Epoch: 5 loss: 0.936287 Recall@20: 0.15457627118644068 MRR@20: 0.051902178037456406
2017-11-24 23:20:11,775 - INFO - Epoch: 10 loss: 0.915295 Recall@20: 0.21898305084745762 MRR@20: 0.07437459269549838
2017-11-24 23:24:20,357 - INFO - Epoch: 15 loss: 0.903306 Recall@20: 0.24813559322033898 MRR@20: 0.08430688547894825
2017-11-24 23:28:28,040 - INFO - Epoch: 20 loss: 0.894980 Recall@20: 0.26915254237288133 MRR@20: 0.08982491372707566
2017-11-24 23:32:35,543 - INFO - Epoch: 25 loss: 0.888685 Recall@20: 0.28 MRR@20: 0.0947293547904347
2017-11-24 23:36:45,882 - INFO - Epoch: 30 loss: 0.883747 Recall@20: 0.2840677966101695 MRR@20: 0.09728128173389756
2017-11-24 23:40:52,551 - INFO - Epoch: 35 loss: 0.879586 Recall@20: 0.29152542372881357 MRR@20: 0.10022694915120268
2017-11-24 23:45:01,162 - INFO - Epoch: 40 loss: 0.876130 Recall@20: 0.29966101694915254 MRR@20: 0.10242197975073036
2017-11-24 23:49:10,046 - INFO - Epoch: 45 loss: 0.873236 Recall@20: 0.3105084745762712 MRR@20: 0.10294203658602567
2017-11-24 23:52:34,796 - INFO - rnn_size:128  batch_size:64  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.01
2017-11-24 23:53:34,035 - INFO - Epoch: 0 loss: 0.979971 Recall@20: 0.06305084745762712 MRR@20: 0.019407349295972893
2017-11-24 23:56:59,711 - INFO - Epoch: 5 loss: 0.902510 Recall@20: 0.24 MRR@20: 0.08109149293215516
2017-11-25 00:00:35,626 - INFO - Epoch: 10 loss: 0.882452 Recall@20: 0.2935593220338983 MRR@20: 0.09553621984820493
2017-11-25 00:04:12,145 - INFO - Epoch: 15 loss: 0.871691 Recall@20: 0.3111864406779661 MRR@20: 0.10228745699386407
2017-11-25 00:07:50,000 - INFO - Epoch: 20 loss: 0.864780 Recall@20: 0.31864406779661014 MRR@20: 0.10553132099049609
2017-11-25 00:11:27,344 - INFO - Epoch: 25 loss: 0.859959 Recall@20: 0.3288135593220339 MRR@20: 0.10872329320408769
2017-11-25 00:15:05,501 - INFO - Epoch: 30 loss: 0.856330 Recall@20: 0.3389830508474576 MRR@20: 0.1133322364230954
2017-11-25 00:18:44,059 - INFO - Epoch: 35 loss: 0.853449 Recall@20: 0.3430508474576271 MRR@20: 0.11492322757440561
2017-11-25 00:22:21,544 - INFO - Epoch: 40 loss: 0.851173 Recall@20: 0.34779661016949154 MRR@20: 0.1170272423028628
2017-11-25 00:25:53,845 - INFO - Epoch: 45 loss: 0.849386 Recall@20: 0.3511864406779661 MRR@20: 0.11913059959287062
2017-11-25 00:28:46,603 - INFO - rnn_size:128  batch_size:64  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.05
2017-11-25 00:29:40,513 - INFO - Epoch: 0 loss: 0.919599 Recall@20: 0.24949152542372882 MRR@20: 0.09131059360607556
2017-11-25 00:33:22,309 - INFO - Epoch: 5 loss: 0.845316 Recall@20: 0.36542372881355933 MRR@20: 0.12772240017071312
2017-11-25 00:37:02,237 - INFO - Epoch: 10 loss: 0.837658 Recall@20: 0.36 MRR@20: 0.13133460158109891
2017-11-25 00:40:42,398 - INFO - Epoch: 15 loss: 0.834675 Recall@20: 0.351864406779661 MRR@20: 0.13024060307932375
2017-11-25 00:44:21,499 - INFO - Epoch: 20 loss: 0.833077 Recall@20: 0.3423728813559322 MRR@20: 0.12535008322212499
2017-11-25 00:48:03,110 - INFO - Epoch: 25 loss: 0.831980 Recall@20: 0.34915254237288135 MRR@20: 0.12835693910842147
2017-11-25 00:51:43,258 - INFO - Epoch: 30 loss: 0.831296 Recall@20: 0.34576271186440677 MRR@20: 0.12426650312075616
2017-11-25 00:55:23,770 - INFO - Epoch: 35 loss: 0.830724 Recall@20: 0.3383050847457627 MRR@20: 0.12292979806804123
2017-11-25 00:58:50,872 - INFO - Epoch: 40 loss: 0.830286 Recall@20: 0.3389830508474576 MRR@20: 0.12326716364626321
2017-11-25 01:02:29,347 - INFO - Epoch: 45 loss: 0.829892 Recall@20: 0.33016949152542374 MRR@20: 0.11931562598776746
2017-11-25 01:05:28,857 - INFO - rnn_size:128  batch_size:128  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.0005
2017-11-25 01:06:13,200 - INFO - Epoch: 0 loss: 0.990107 Recall@20: 0.05830508474576271 MRR@20: 0.020358977705228428
2017-11-25 01:09:04,090 - INFO - Epoch: 5 loss: 0.922942 Recall@20: 0.15322033898305085 MRR@20: 0.05653679647563784
2017-11-25 01:11:55,630 - INFO - Epoch: 10 loss: 0.899412 Recall@20: 0.21152542372881356 MRR@20: 0.07436709879300528
2017-11-25 01:14:46,281 - INFO - Epoch: 15 loss: 0.886155 Recall@20: 0.24949152542372882 MRR@20: 0.08427669152662592
2017-11-25 01:17:37,465 - INFO - Epoch: 20 loss: 0.877310 Recall@20: 0.271864406779661 MRR@20: 0.09581323263560762
2017-11-25 01:20:28,134 - INFO - Epoch: 25 loss: 0.870835 Recall@20: 0.28135593220338984 MRR@20: 0.09569428206084028
2017-11-25 01:23:19,157 - INFO - Epoch: 30 loss: 0.865817 Recall@20: 0.29559322033898305 MRR@20: 0.09962674333648253
2017-11-25 01:26:10,252 - INFO - Epoch: 35 loss: 0.861716 Recall@20: 0.30033898305084744 MRR@20: 0.09930172062462034
2017-11-25 01:28:47,674 - INFO - Epoch: 40 loss: 0.858473 Recall@20: 0.31186440677966104 MRR@20: 0.10355585569619784
2017-11-25 01:31:36,993 - INFO - Epoch: 45 loss: 0.855672 Recall@20: 0.3152542372881356 MRR@20: 0.10419682189388857
2017-11-25 01:33:56,151 - INFO - rnn_size:128  batch_size:128  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.001
2017-11-25 01:34:40,286 - INFO - Epoch: 0 loss: 0.980234 Recall@20: 0.07457627118644068 MRR@20: 0.022505236372135674
2017-11-25 01:37:32,464 - INFO - Epoch: 5 loss: 0.899630 Recall@20: 0.22033898305084745 MRR@20: 0.07616604806981046
2017-11-25 01:40:24,440 - INFO - Epoch: 10 loss: 0.878288 Recall@20: 0.25898305084745765 MRR@20: 0.09560183009343422
2017-11-25 01:43:15,594 - INFO - Epoch: 15 loss: 0.866780 Recall@20: 0.29559322033898305 MRR@20: 0.10205355008054805
2017-11-25 01:46:07,912 - INFO - Epoch: 20 loss: 0.859451 Recall@20: 0.3105084745762712 MRR@20: 0.10598666674145499
2017-11-25 01:48:59,069 - INFO - Epoch: 25 loss: 0.854269 Recall@20: 0.3233898305084746 MRR@20: 0.10806664156131544
2017-11-25 01:51:49,893 - INFO - Epoch: 30 loss: 0.850507 Recall@20: 0.33491525423728813 MRR@20: 0.11257638006055913
2017-11-25 01:54:40,801 - INFO - Epoch: 35 loss: 0.847547 Recall@20: 0.3376271186440678 MRR@20: 0.11309162632508386
2017-11-25 01:57:32,481 - INFO - Epoch: 40 loss: 0.845278 Recall@20: 0.34576271186440677 MRR@20: 0.1146971874422942
2017-11-25 02:00:12,138 - INFO - Epoch: 45 loss: 0.843443 Recall@20: 0.34915254237288135 MRR@20: 0.11471639948094794
2017-11-25 02:02:37,374 - INFO - rnn_size:128  batch_size:128  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.005
2017-11-25 02:03:20,758 - INFO - Epoch: 0 loss: 0.942936 Recall@20: 0.17559322033898306 MRR@20: 0.06722192510165434
2017-11-25 02:06:12,067 - INFO - Epoch: 5 loss: 0.862161 Recall@20: 0.3383050847457627 MRR@20: 0.11781904102497584
2017-11-25 02:09:03,532 - INFO - Epoch: 10 loss: 0.850044 Recall@20: 0.3579661016949153 MRR@20: 0.11806967621767955
2017-11-25 02:11:53,620 - INFO - Epoch: 15 loss: 0.845430 Recall@20: 0.3511864406779661 MRR@20: 0.1152445801736351
2017-11-25 02:14:43,740 - INFO - Epoch: 20 loss: 0.843251 Recall@20: 0.351864406779661 MRR@20: 0.11830955385009014
2017-11-25 02:17:34,146 - INFO - Epoch: 25 loss: 0.841882 Recall@20: 0.34915254237288135 MRR@20: 0.11916061888762207
2017-11-25 02:20:25,494 - INFO - Epoch: 30 loss: 0.840966 Recall@20: 0.34847457627118644 MRR@20: 0.1204907432681479
2017-11-25 02:23:15,794 - INFO - Epoch: 35 loss: 0.840382 Recall@20: 0.3383050847457627 MRR@20: 0.1156598043645323
2017-11-25 02:26:08,911 - INFO - Epoch: 40 loss: 0.839946 Recall@20: 0.3389830508474576 MRR@20: 0.11608817502659659
2017-11-25 02:29:00,519 - INFO - Epoch: 45 loss: 0.839500 Recall@20: 0.3389830508474576 MRR@20: 0.11537600811145964
2017-11-25 02:31:14,148 - INFO - rnn_size:128  batch_size:128  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.005
2017-11-25 02:31:44,053 - INFO - Epoch: 0 loss: 0.995499 Recall@20: 0.031864406779661014 MRR@20: 0.01673769666690903
2017-11-25 02:33:30,423 - INFO - Epoch: 5 loss: 0.954916 Recall@20: 0.12406779661016949 MRR@20: 0.04236259253622952
2017-11-25 02:35:17,522 - INFO - Epoch: 10 loss: 0.929434 Recall@20: 0.18169491525423728 MRR@20: 0.05847428190567194
2017-11-25 02:37:04,142 - INFO - Epoch: 15 loss: 0.915330 Recall@20: 0.21559322033898304 MRR@20: 0.07385185719110261
2017-11-25 02:38:51,029 - INFO - Epoch: 20 loss: 0.905752 Recall@20: 0.24745762711864408 MRR@20: 0.08280407595937321
2017-11-25 02:40:38,624 - INFO - Epoch: 25 loss: 0.898563 Recall@20: 0.2725423728813559 MRR@20: 0.08745471286044304
2017-11-25 02:42:25,168 - INFO - Epoch: 30 loss: 0.892872 Recall@20: 0.28338983050847455 MRR@20: 0.09049549248219027
2017-11-25 02:44:12,827 - INFO - Epoch: 35 loss: 0.888163 Recall@20: 0.288135593220339 MRR@20: 0.09357413452312963
2017-11-25 02:45:59,586 - INFO - Epoch: 40 loss: 0.884281 Recall@20: 0.29694915254237286 MRR@20: 0.09695258113059971
2017-11-25 02:47:46,296 - INFO - Epoch: 45 loss: 0.880919 Recall@20: 0.3050847457627119 MRR@20: 0.09942285992330595
2017-11-25 02:49:15,835 - INFO - rnn_size:128  batch_size:128  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.01
2017-11-25 02:49:46,761 - INFO - Epoch: 0 loss: 0.992805 Recall@20: 0.05016949152542373 MRR@20: 0.017361188329782548
2017-11-25 02:51:25,822 - INFO - Epoch: 5 loss: 0.916643 Recall@20: 0.2176271186440678 MRR@20: 0.0774353804847849
2017-11-25 02:53:11,936 - INFO - Epoch: 10 loss: 0.893161 Recall@20: 0.2711864406779661 MRR@20: 0.09255468928347661
2017-11-25 02:54:59,206 - INFO - Epoch: 15 loss: 0.880646 Recall@20: 0.2935593220338983 MRR@20: 0.10128751923593714
2017-11-25 02:56:45,830 - INFO - Epoch: 20 loss: 0.872660 Recall@20: 0.31457627118644066 MRR@20: 0.10426507747090734
2017-11-25 02:58:32,839 - INFO - Epoch: 25 loss: 0.866987 Recall@20: 0.32949152542372884 MRR@20: 0.10610564931386679
2017-11-25 03:00:20,338 - INFO - Epoch: 30 loss: 0.862733 Recall@20: 0.34372881355932206 MRR@20: 0.10720255120215764
2017-11-25 03:02:07,501 - INFO - Epoch: 35 loss: 0.859420 Recall@20: 0.34779661016949154 MRR@20: 0.11137986829365323
2017-11-25 03:03:54,287 - INFO - Epoch: 40 loss: 0.856829 Recall@20: 0.3464406779661017 MRR@20: 0.11624479848103714
2017-11-25 03:05:41,673 - INFO - Epoch: 45 loss: 0.854620 Recall@20: 0.34983050847457625 MRR@20: 0.11733085380566619
2017-11-25 03:07:12,119 - INFO - rnn_size:128  batch_size:128  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.05
2017-11-25 03:07:42,918 - INFO - Epoch: 0 loss: 0.937057 Recall@20: 0.2094915254237288 MRR@20: 0.07353382513599233
2017-11-25 03:09:30,118 - INFO - Epoch: 5 loss: 0.853170 Recall@20: 0.34508474576271186 MRR@20: 0.12542489402058063
2017-11-25 03:11:17,106 - INFO - Epoch: 10 loss: 0.842742 Recall@20: 0.3552542372881356 MRR@20: 0.12382800154199115
2017-11-25 03:12:55,179 - INFO - Epoch: 15 loss: 0.838789 Recall@20: 0.3552542372881356 MRR@20: 0.12276325059092545
2017-11-25 03:14:42,691 - INFO - Epoch: 20 loss: 0.836793 Recall@20: 0.34711864406779663 MRR@20: 0.12251137917722375
2017-11-25 03:16:31,360 - INFO - Epoch: 25 loss: 0.835442 Recall@20: 0.34508474576271186 MRR@20: 0.1205485166853693
2017-11-25 03:18:19,649 - INFO - Epoch: 30 loss: 0.834602 Recall@20: 0.3389830508474576 MRR@20: 0.11787217039197939
2017-11-25 03:20:06,200 - INFO - Epoch: 35 loss: 0.833964 Recall@20: 0.3376271186440678 MRR@20: 0.11809040926714223
2017-11-25 03:21:53,947 - INFO - Epoch: 40 loss: 0.833410 Recall@20: 0.3410169491525424 MRR@20: 0.11614008968589959
2017-11-25 03:23:42,141 - INFO - Epoch: 45 loss: 0.832971 Recall@20: 0.33559322033898303 MRR@20: 0.11611419839598461
2017-11-25 03:25:12,816 - INFO - rnn_size:128  batch_size:256  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.0005
2017-11-25 03:25:39,528 - INFO - Epoch: 0 loss: 0.992433 Recall@20: 0.05559322033898305 MRR@20: 0.019110654395484115
2017-11-25 03:27:04,053 - INFO - Epoch: 5 loss: 0.924091 Recall@20: 0.16135593220338984 MRR@20: 0.05809410050573403
2017-11-25 03:28:27,943 - INFO - Epoch: 10 loss: 0.900886 Recall@20: 0.22576271186440677 MRR@20: 0.07709294681693275
2017-11-25 03:29:52,451 - INFO - Epoch: 15 loss: 0.887783 Recall@20: 0.25152542372881354 MRR@20: 0.08979949407842044
2017-11-25 03:31:15,604 - INFO - Epoch: 20 loss: 0.878996 Recall@20: 0.26372881355932204 MRR@20: 0.0950092614760191
2017-11-25 03:32:30,238 - INFO - Epoch: 25 loss: 0.872539 Recall@20: 0.28135593220338984 MRR@20: 0.09857453301568325
2017-11-25 03:33:54,048 - INFO - Epoch: 30 loss: 0.867567 Recall@20: 0.2901694915254237 MRR@20: 0.10084805696189963
2017-11-25 03:35:18,003 - INFO - Epoch: 35 loss: 0.863520 Recall@20: 0.29898305084745763 MRR@20: 0.10250883717741041
2017-11-25 03:36:41,383 - INFO - Epoch: 40 loss: 0.860262 Recall@20: 0.30847457627118646 MRR@20: 0.10243549795898013
2017-11-25 03:38:05,323 - INFO - Epoch: 45 loss: 0.857553 Recall@20: 0.3193220338983051 MRR@20: 0.10943680591912214
2017-11-25 03:39:17,085 - INFO - rnn_size:128  batch_size:256  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.001
2017-11-25 03:39:43,868 - INFO - Epoch: 0 loss: 0.983152 Recall@20: 0.07254237288135593 MRR@20: 0.02512649313045493
2017-11-25 03:41:07,963 - INFO - Epoch: 5 loss: 0.901116 Recall@20: 0.22305084745762713 MRR@20: 0.0788688052515255
2017-11-25 03:42:32,215 - INFO - Epoch: 10 loss: 0.880013 Recall@20: 0.26237288135593223 MRR@20: 0.09285427042274917
2017-11-25 03:43:56,378 - INFO - Epoch: 15 loss: 0.868755 Recall@20: 0.29627118644067796 MRR@20: 0.10226933420896268
2017-11-25 03:45:19,644 - INFO - Epoch: 20 loss: 0.861520 Recall@20: 0.3111864406779661 MRR@20: 0.1070493096922493
2017-11-25 03:46:42,687 - INFO - Epoch: 25 loss: 0.856419 Recall@20: 0.3233898305084746 MRR@20: 0.11146290024132813
2017-11-25 03:48:07,006 - INFO - Epoch: 30 loss: 0.852627 Recall@20: 0.3335593220338983 MRR@20: 0.11177064694239484
2017-11-25 03:49:30,224 - INFO - Epoch: 35 loss: 0.849711 Recall@20: 0.3369491525423729 MRR@20: 0.11936848121239685
2017-11-25 03:50:53,547 - INFO - Epoch: 40 loss: 0.847424 Recall@20: 0.3423728813559322 MRR@20: 0.1188394858888641
2017-11-25 03:52:09,017 - INFO - Epoch: 45 loss: 0.845653 Recall@20: 0.3369491525423729 MRR@20: 0.12248188558801457
2017-11-25 03:53:18,560 - INFO - rnn_size:128  batch_size:256  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.005
2017-11-25 03:53:45,423 - INFO - Epoch: 0 loss: 0.945684 Recall@20: 0.1694915254237288 MRR@20: 0.054568529407774825
2017-11-25 03:55:08,862 - INFO - Epoch: 5 loss: 0.865057 Recall@20: 0.34779661016949154 MRR@20: 0.12474593303590527
2017-11-25 03:56:33,268 - INFO - Epoch: 10 loss: 0.853029 Recall@20: 0.34915254237288135 MRR@20: 0.119270865424536
2017-11-25 03:57:57,353 - INFO - Epoch: 15 loss: 0.848424 Recall@20: 0.3396610169491525 MRR@20: 0.11782414358772128
2017-11-25 03:59:21,236 - INFO - Epoch: 20 loss: 0.846104 Recall@20: 0.3389830508474576 MRR@20: 0.1247646946000307
2017-11-25 04:00:44,552 - INFO - Epoch: 25 loss: 0.844555 Recall@20: 0.3416949152542373 MRR@20: 0.11602253515726259
2017-11-25 04:02:09,376 - INFO - Epoch: 30 loss: 0.843590 Recall@20: 0.3383050847457627 MRR@20: 0.12023432533777817
2017-11-25 04:03:33,389 - INFO - Epoch: 35 loss: 0.842803 Recall@20: 0.3410169491525424 MRR@20: 0.11678502981221144
2017-11-25 04:04:56,690 - INFO - Epoch: 40 loss: 0.842294 Recall@20: 0.3369491525423729 MRR@20: 0.11779512309884352
2017-11-25 04:06:20,501 - INFO - Epoch: 45 loss: 0.841813 Recall@20: 0.34576271186440677 MRR@20: 0.12082142529943861
2017-11-25 04:07:31,709 - INFO - rnn_size:128  batch_size:256  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.005
2017-11-25 04:07:54,287 - INFO - Epoch: 0 loss: 0.997805 Recall@20: 0.010847457627118645 MRR@20: 0.007723496178132269
2017-11-25 04:09:01,671 - INFO - Epoch: 5 loss: 0.980468 Recall@20: 0.06440677966101695 MRR@20: 0.022542238859366424
2017-11-25 04:10:09,084 - INFO - Epoch: 10 loss: 0.950932 Recall@20: 0.11661016949152542 MRR@20: 0.03802837794111342
2017-11-25 04:11:15,765 - INFO - Epoch: 15 loss: 0.933412 Recall@20: 0.1552542372881356 MRR@20: 0.056083554542860826
2017-11-25 04:12:17,324 - INFO - Epoch: 20 loss: 0.921762 Recall@20: 0.19186440677966102 MRR@20: 0.06811709094576282
2017-11-25 04:13:57,247 - INFO - Epoch: 25 loss: 0.913089 Recall@20: 0.22372881355932203 MRR@20: 0.07903152612839341
2017-11-25 04:15:37,769 - INFO - Epoch: 30 loss: 0.906301 Recall@20: 0.24745762711864408 MRR@20: 0.08423184810501806
2017-11-25 04:17:19,309 - INFO - Epoch: 35 loss: 0.900771 Recall@20: 0.2684745762711864 MRR@20: 0.09066852931574558
2017-11-25 04:19:00,964 - INFO - Epoch: 40 loss: 0.896113 Recall@20: 0.28271186440677964 MRR@20: 0.09381624229845356
2017-11-25 04:20:41,872 - INFO - Epoch: 45 loss: 0.892103 Recall@20: 0.2847457627118644 MRR@20: 0.09481519377347683
2017-11-25 04:22:08,040 - INFO - rnn_size:128  batch_size:256  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.01
2017-11-25 04:22:37,711 - INFO - Epoch: 0 loss: 0.997325 Recall@20: 0.029152542372881354 MRR@20: 0.013310956740169102
2017-11-25 04:24:19,783 - INFO - Epoch: 5 loss: 0.941271 Recall@20: 0.14101694915254237 MRR@20: 0.05005158389854303
2017-11-25 04:26:02,919 - INFO - Epoch: 10 loss: 0.911394 Recall@20: 0.2216949152542373 MRR@20: 0.07819589269534173
2017-11-25 04:27:44,299 - INFO - Epoch: 15 loss: 0.895725 Recall@20: 0.26576271186440675 MRR@20: 0.093367418609272
2017-11-25 04:29:26,890 - INFO - Epoch: 20 loss: 0.885638 Recall@20: 0.28338983050847455 MRR@20: 0.0973078873689673
2017-11-25 04:31:08,614 - INFO - Epoch: 25 loss: 0.878367 Recall@20: 0.2976271186440678 MRR@20: 0.10137153866639094
2017-11-25 04:32:51,765 - INFO - Epoch: 30 loss: 0.872935 Recall@20: 0.3105084745762712 MRR@20: 0.10610098290577905
2017-11-25 04:34:34,299 - INFO - Epoch: 35 loss: 0.868670 Recall@20: 0.3206779661016949 MRR@20: 0.10767657713832346
2017-11-25 04:36:16,856 - INFO - Epoch: 40 loss: 0.865218 Recall@20: 0.32745762711864407 MRR@20: 0.109895055863309
2017-11-25 04:37:57,949 - INFO - Epoch: 45 loss: 0.862390 Recall@20: 0.3376271186440678 MRR@20: 0.11258858836032579
2017-11-25 04:39:24,091 - INFO - rnn_size:128  batch_size:256  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.05
2017-11-25 04:39:54,209 - INFO - Epoch: 0 loss: 0.961347 Recall@20: 0.13966101694915253 MRR@20: 0.04254824567373762
2017-11-25 04:41:36,543 - INFO - Epoch: 5 loss: 0.865415 Recall@20: 0.3152542372881356 MRR@20: 0.11531151857011121
2017-11-25 04:43:19,522 - INFO - Epoch: 10 loss: 0.850097 Recall@20: 0.34372881355932206 MRR@20: 0.12587014759741316
2017-11-25 04:45:01,342 - INFO - Epoch: 15 loss: 0.843794 Recall@20: 0.34915254237288135 MRR@20: 0.12694844576633424
2017-11-25 04:46:44,234 - INFO - Epoch: 20 loss: 0.840463 Recall@20: 0.3545762711864407 MRR@20: 0.12690200469916585
2017-11-25 04:48:26,406 - INFO - Epoch: 25 loss: 0.838561 Recall@20: 0.3552542372881356 MRR@20: 0.12597174505775022
2017-11-25 04:50:09,444 - INFO - Epoch: 30 loss: 0.837274 Recall@20: 0.3511864406779661 MRR@20: 0.1229415799315574
2017-11-25 04:51:51,010 - INFO - Epoch: 35 loss: 0.836372 Recall@20: 0.34576271186440677 MRR@20: 0.12164137194482998
2017-11-25 04:53:32,748 - INFO - Epoch: 40 loss: 0.835682 Recall@20: 0.34915254237288135 MRR@20: 0.12338613718757496
2017-11-25 04:55:15,071 - INFO - Epoch: 45 loss: 0.835191 Recall@20: 0.34711864406779663 MRR@20: 0.12174728992591195
2017-11-25 04:56:42,262 - INFO - rnn_size:256  batch_size:64  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.0005
2017-11-25 04:58:26,620 - INFO - Epoch: 0 loss: 0.983305 Recall@20: 0.05694915254237288 MRR@20: 0.0227831272090337
2017-11-25 05:06:15,139 - INFO - Epoch: 5 loss: 0.907845 Recall@20: 0.17423728813559322 MRR@20: 0.06664808842134758
2017-11-25 05:14:04,015 - INFO - Epoch: 10 loss: 0.883205 Recall@20: 0.24271186440677966 MRR@20: 0.08614285030473307
2017-11-25 05:21:53,749 - INFO - Epoch: 15 loss: 0.869129 Recall@20: 0.2725423728813559 MRR@20: 0.09646799817931159
2017-11-25 05:29:41,414 - INFO - Epoch: 20 loss: 0.859724 Recall@20: 0.29152542372881357 MRR@20: 0.10732479336094805
2017-11-25 05:37:09,205 - INFO - Epoch: 25 loss: 0.852571 Recall@20: 0.31254237288135595 MRR@20: 0.1144258703870395
2017-11-25 05:44:58,739 - INFO - Epoch: 30 loss: 0.846992 Recall@20: 0.3254237288135593 MRR@20: 0.12025779333689815
2017-11-25 05:52:47,513 - INFO - Epoch: 35 loss: 0.842510 Recall@20: 0.3335593220338983 MRR@20: 0.1217389847679505
2017-11-25 06:00:36,252 - INFO - Epoch: 40 loss: 0.838771 Recall@20: 0.3403389830508475 MRR@20: 0.12531975155790548
2017-11-25 06:08:24,482 - INFO - Epoch: 45 loss: 0.835642 Recall@20: 0.3525423728813559 MRR@20: 0.12801274930663084
2017-11-25 06:14:43,153 - INFO - rnn_size:256  batch_size:64  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.001
2017-11-25 06:16:27,090 - INFO - Epoch: 0 loss: 0.970755 Recall@20: 0.09016949152542372 MRR@20: 0.031029876445524237
2017-11-25 06:24:15,524 - INFO - Epoch: 5 loss: 0.884073 Recall@20: 0.23457627118644067 MRR@20: 0.08334559992024441
2017-11-25 06:32:04,274 - INFO - Epoch: 10 loss: 0.861224 Recall@20: 0.29084745762711867 MRR@20: 0.1119309500269253
2017-11-25 06:39:50,978 - INFO - Epoch: 15 loss: 0.848614 Recall@20: 0.3227118644067797 MRR@20: 0.12024194544268534
2017-11-25 06:47:39,424 - INFO - Epoch: 20 loss: 0.840310 Recall@20: 0.336271186440678 MRR@20: 0.12602257989338853
2017-11-25 06:55:06,150 - INFO - Epoch: 25 loss: 0.834488 Recall@20: 0.34915254237288135 MRR@20: 0.12941124930412334
2017-11-25 07:02:53,720 - INFO - Epoch: 30 loss: 0.830202 Recall@20: 0.3593220338983051 MRR@20: 0.13491151152928976
2017-11-25 07:10:43,123 - INFO - Epoch: 35 loss: 0.827085 Recall@20: 0.36203389830508476 MRR@20: 0.1347064437518601
2017-11-25 07:18:29,708 - INFO - Epoch: 40 loss: 0.824715 Recall@20: 0.36203389830508476 MRR@20: 0.1352383792474048
2017-11-25 07:26:18,481 - INFO - Epoch: 45 loss: 0.822960 Recall@20: 0.36338983050847457 MRR@20: 0.13642883522930224
2017-11-25 07:32:37,166 - INFO - rnn_size:256  batch_size:64  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.005
2017-11-25 07:34:21,014 - INFO - Epoch: 0 loss: 0.933175 Recall@20: 0.2128813559322034 MRR@20: 0.07750809909103448
2017-11-25 07:42:12,438 - INFO - Epoch: 5 loss: 0.846549 Recall@20: 0.34847457627118644 MRR@20: 0.12796739177633337
2017-11-25 07:50:02,369 - INFO - Epoch: 10 loss: 0.833739 Recall@20: 0.3572881355932203 MRR@20: 0.1305331990282665
2017-11-25 07:57:53,696 - INFO - Epoch: 15 loss: 0.829706 Recall@20: 0.3545762711864407 MRR@20: 0.12536114307526386
2017-11-25 08:05:45,187 - INFO - Epoch: 20 loss: 0.827922 Recall@20: 0.3464406779661017 MRR@20: 0.1254496769781442
2017-11-25 08:13:36,961 - INFO - Epoch: 25 loss: 0.826778 Recall@20: 0.34711864406779663 MRR@20: 0.13221206508300493
2017-11-25 08:21:05,950 - INFO - Epoch: 30 loss: 0.826148 Recall@20: 0.3410169491525424 MRR@20: 0.12435843238522044
2017-11-25 08:28:56,484 - INFO - Epoch: 35 loss: 0.825686 Recall@20: 0.34779661016949154 MRR@20: 0.12482103963273615
2017-11-25 08:36:48,624 - INFO - Epoch: 40 loss: 0.825303 Recall@20: 0.33152542372881355 MRR@20: 0.12584660524097474
2017-11-25 08:44:39,481 - INFO - Epoch: 45 loss: 0.825102 Recall@20: 0.336271186440678 MRR@20: 0.1220109520857015
2017-11-25 08:51:00,776 - INFO - rnn_size:256  batch_size:64  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.005
2017-11-25 08:52:18,160 - INFO - Epoch: 0 loss: 0.989435 Recall@20: 0.0671186440677966 MRR@20: 0.029608277329009867
2017-11-25 08:58:02,494 - INFO - Epoch: 5 loss: 0.924304 Recall@20: 0.18305084745762712 MRR@20: 0.06413215388565653
2017-11-25 09:03:46,552 - INFO - Epoch: 10 loss: 0.900777 Recall@20: 0.22779661016949151 MRR@20: 0.08546161647672904
2017-11-25 09:09:33,161 - INFO - Epoch: 15 loss: 0.887671 Recall@20: 0.2738983050847458 MRR@20: 0.09722827012067185
2017-11-25 09:15:18,074 - INFO - Epoch: 20 loss: 0.878740 Recall@20: 0.2888135593220339 MRR@20: 0.10227458856757804
2017-11-25 09:20:56,281 - INFO - Epoch: 25 loss: 0.872121 Recall@20: 0.30101694915254235 MRR@20: 0.10490118344862007
2017-11-25 09:26:39,729 - INFO - Epoch: 30 loss: 0.866938 Recall@20: 0.3105084745762712 MRR@20: 0.10757713611011613
2017-11-25 09:32:25,912 - INFO - Epoch: 35 loss: 0.862722 Recall@20: 0.31661016949152543 MRR@20: 0.11131949138883603
2017-11-25 09:41:03,785 - INFO - Epoch: 40 loss: 0.859262 Recall@20: 0.32677966101694916 MRR@20: 0.11405054950704842
2017-11-25 09:53:01,030 - INFO - Epoch: 45 loss: 0.856307 Recall@20: 0.3342372881355932 MRR@20: 0.11632922975120066
2017-11-25 10:00:31,502 - INFO - rnn_size:256  batch_size:64  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.01
2017-11-25 10:01:50,952 - INFO - Epoch: 0 loss: 0.976036 Recall@20: 0.08542372881355932 MRR@20: 0.02526554090816567
2017-11-25 10:10:55,752 - INFO - Epoch: 5 loss: 0.888077 Recall@20: 0.26440677966101694 MRR@20: 0.09668913606377527
2017-11-25 10:16:34,154 - INFO - Epoch: 10 loss: 0.866735 Recall@20: 0.30983050847457627 MRR@20: 0.10594018085370344
2017-11-25 10:22:12,807 - INFO - Epoch: 15 loss: 0.855697 Recall@20: 0.3288135593220339 MRR@20: 0.11377700531730547
2017-11-25 10:27:52,609 - INFO - Epoch: 20 loss: 0.848759 Recall@20: 0.3430508474576271 MRR@20: 0.11888993901272855
2017-11-25 10:33:29,717 - INFO - Epoch: 25 loss: 0.843916 Recall@20: 0.34847457627118644 MRR@20: 0.12244374421238563
2017-11-25 10:39:07,641 - INFO - Epoch: 30 loss: 0.840259 Recall@20: 0.351864406779661 MRR@20: 0.125980010555757
2017-11-25 10:44:47,238 - INFO - Epoch: 35 loss: 0.837434 Recall@20: 0.3545762711864407 MRR@20: 0.1275146296393082
2017-11-25 10:50:26,570 - INFO - Epoch: 40 loss: 0.835170 Recall@20: 0.3572881355932203 MRR@20: 0.12829862707534956
2017-11-25 10:56:05,885 - INFO - Epoch: 45 loss: 0.833303 Recall@20: 0.3586440677966102 MRR@20: 0.12799771947979954
2017-11-25 11:00:41,205 - INFO - rnn_size:256  batch_size:64  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.05
2017-11-25 11:01:57,655 - INFO - Epoch: 0 loss: 0.913611 Recall@20: 0.2684745762711864 MRR@20: 0.1014792245384416
2017-11-25 11:06:43,343 - INFO - Epoch: 5 loss: 0.830363 Recall@20: 0.36203389830508476 MRR@20: 0.13801999945096965
2017-11-25 11:11:34,476 - INFO - Epoch: 10 loss: 0.822127 Recall@20: 0.3505084745762712 MRR@20: 0.13570907678201588
2017-11-25 11:16:25,771 - INFO - Epoch: 15 loss: 0.818993 Recall@20: 0.351864406779661 MRR@20: 0.12967324549244577
2017-11-25 11:21:17,776 - INFO - Epoch: 20 loss: 0.817213 Recall@20: 0.35322033898305083 MRR@20: 0.12941369747485615
2017-11-25 11:26:09,458 - INFO - Epoch: 25 loss: 0.816180 Recall@20: 0.3464406779661017 MRR@20: 0.13175747377109082
2017-11-25 11:31:03,027 - INFO - Epoch: 30 loss: 0.815296 Recall@20: 0.3410169491525424 MRR@20: 0.12887117217730634
2017-11-25 11:35:55,176 - INFO - Epoch: 35 loss: 0.814684 Recall@20: 0.3416949152542373 MRR@20: 0.1304578568481596
2017-11-25 11:40:48,330 - INFO - Epoch: 40 loss: 0.814206 Recall@20: 0.3376271186440678 MRR@20: 0.1278887590023918
2017-11-25 11:45:41,621 - INFO - Epoch: 45 loss: 0.813894 Recall@20: 0.3376271186440678 MRR@20: 0.12821591441098706
2017-11-25 11:49:23,302 - INFO - rnn_size:256  batch_size:128  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.0005
2017-11-25 11:50:22,145 - INFO - Epoch: 0 loss: 0.987368 Recall@20: 0.06372881355932203 MRR@20: 0.02489560794863308
2017-11-25 11:54:25,782 - INFO - Epoch: 5 loss: 0.910215 Recall@20: 0.18440677966101696 MRR@20: 0.06872125157555707
2017-11-25 11:58:28,430 - INFO - Epoch: 10 loss: 0.885622 Recall@20: 0.2447457627118644 MRR@20: 0.08978850137461146
2017-11-25 12:02:31,345 - INFO - Epoch: 15 loss: 0.871721 Recall@20: 0.27728813559322035 MRR@20: 0.10005634847215368
2017-11-25 12:06:34,394 - INFO - Epoch: 20 loss: 0.862348 Recall@20: 0.3016949152542373 MRR@20: 0.10991224642667684
2017-11-25 12:10:36,032 - INFO - Epoch: 25 loss: 0.855333 Recall@20: 0.31728813559322033 MRR@20: 0.11509234168663779
2017-11-25 12:14:38,950 - INFO - Epoch: 30 loss: 0.849843 Recall@20: 0.328135593220339 MRR@20: 0.12026611592799873
2017-11-25 12:18:41,737 - INFO - Epoch: 35 loss: 0.845397 Recall@20: 0.34440677966101696 MRR@20: 0.12031775720795504
2017-11-25 12:22:44,162 - INFO - Epoch: 40 loss: 0.841790 Recall@20: 0.3511864406779661 MRR@20: 0.12347292220527774
2017-11-25 12:26:45,860 - INFO - Epoch: 45 loss: 0.838643 Recall@20: 0.3552542372881356 MRR@20: 0.1241365181494268
2017-11-25 12:30:04,134 - INFO - rnn_size:256  batch_size:128  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.001
2017-11-25 12:30:46,378 - INFO - Epoch: 0 loss: 0.974470 Recall@20: 0.09491525423728814 MRR@20: 0.03033897308489322
2017-11-25 12:34:48,898 - INFO - Epoch: 5 loss: 0.886426 Recall@20: 0.24203389830508473 MRR@20: 0.08893389480622518
2017-11-25 12:38:51,959 - INFO - Epoch: 10 loss: 0.863851 Recall@20: 0.29152542372881357 MRR@20: 0.11151038062472182
2017-11-25 12:42:55,409 - INFO - Epoch: 15 loss: 0.851478 Recall@20: 0.31796610169491524 MRR@20: 0.11712321367332648
2017-11-25 12:46:57,895 - INFO - Epoch: 20 loss: 0.843312 Recall@20: 0.3369491525423729 MRR@20: 0.12098753897213782
2017-11-25 12:50:58,941 - INFO - Epoch: 25 loss: 0.837565 Recall@20: 0.34576271186440677 MRR@20: 0.1220243600510432
2017-11-25 12:55:00,937 - INFO - Epoch: 30 loss: 0.833426 Recall@20: 0.3545762711864407 MRR@20: 0.12610477274091694
2017-11-25 12:59:03,043 - INFO - Epoch: 35 loss: 0.830366 Recall@20: 0.3579661016949153 MRR@20: 0.12808375885657197
2017-11-25 13:03:04,497 - INFO - Epoch: 40 loss: 0.828118 Recall@20: 0.36135593220338985 MRR@20: 0.1275315341926036
2017-11-25 13:07:07,226 - INFO - Epoch: 45 loss: 0.826310 Recall@20: 0.3579661016949153 MRR@20: 0.12704021421256556
2017-11-25 13:10:26,377 - INFO - rnn_size:256  batch_size:128  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.005
2017-11-25 13:11:26,188 - INFO - Epoch: 0 loss: 0.935835 Recall@20: 0.2176271186440678 MRR@20: 0.07704549422870774
2017-11-25 13:15:11,452 - INFO - Epoch: 5 loss: 0.849682 Recall@20: 0.3559322033898305 MRR@20: 0.1300818411064252
2017-11-25 13:19:14,074 - INFO - Epoch: 10 loss: 0.837128 Recall@20: 0.3538983050847458 MRR@20: 0.13001081273416895
2017-11-25 13:23:17,607 - INFO - Epoch: 15 loss: 0.833136 Recall@20: 0.3430508474576271 MRR@20: 0.12169863099999007
2017-11-25 13:27:21,544 - INFO - Epoch: 20 loss: 0.831165 Recall@20: 0.3342372881355932 MRR@20: 0.12323800814811993
2017-11-25 13:31:23,973 - INFO - Epoch: 25 loss: 0.830058 Recall@20: 0.3403389830508475 MRR@20: 0.1208873050273323
2017-11-25 13:35:28,055 - INFO - Epoch: 30 loss: 0.829249 Recall@20: 0.33559322033898303 MRR@20: 0.11771402425797134
2017-11-25 13:39:31,956 - INFO - Epoch: 35 loss: 0.828672 Recall@20: 0.3335593220338983 MRR@20: 0.11987624396849353
2017-11-25 13:43:32,747 - INFO - Epoch: 40 loss: 0.828338 Recall@20: 0.33152542372881355 MRR@20: 0.11973804491905453
2017-11-25 13:47:36,481 - INFO - Epoch: 45 loss: 0.827968 Recall@20: 0.3288135593220339 MRR@20: 0.11696333250804047
2017-11-25 13:50:55,667 - INFO - rnn_size:256  batch_size:128  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.005
2017-11-25 13:51:40,933 - INFO - Epoch: 0 loss: 0.995202 Recall@20: 0.03932203389830508 MRR@20: 0.02207502471699355
2017-11-25 13:54:36,266 - INFO - Epoch: 5 loss: 0.946374 Recall@20: 0.13152542372881357 MRR@20: 0.0515147126025281
2017-11-25 13:57:32,764 - INFO - Epoch: 10 loss: 0.917964 Recall@20: 0.1911864406779661 MRR@20: 0.06763721086770359
2017-11-25 14:00:09,948 - INFO - Epoch: 15 loss: 0.902469 Recall@20: 0.22847457627118645 MRR@20: 0.08045209542575339
2017-11-25 14:02:59,491 - INFO - Epoch: 20 loss: 0.892028 Recall@20: 0.256271186440678 MRR@20: 0.08935277559950908
2017-11-25 14:05:52,746 - INFO - Epoch: 25 loss: 0.884263 Recall@20: 0.27728813559322035 MRR@20: 0.09507453012375087
2017-11-25 14:08:45,808 - INFO - Epoch: 30 loss: 0.878166 Recall@20: 0.29084745762711867 MRR@20: 0.10006267224289474
2017-11-25 14:11:39,106 - INFO - Epoch: 35 loss: 0.873224 Recall@20: 0.3030508474576271 MRR@20: 0.1025514461779089
2017-11-25 14:14:34,978 - INFO - Epoch: 40 loss: 0.869114 Recall@20: 0.31186440677966104 MRR@20: 0.10776494687089222
2017-11-25 14:17:29,242 - INFO - Epoch: 45 loss: 0.865589 Recall@20: 0.31322033898305085 MRR@20: 0.10970233345974542
2017-11-25 14:19:52,579 - INFO - rnn_size:256  batch_size:128  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.01
2017-11-25 14:20:35,166 - INFO - Epoch: 0 loss: 0.991376 Recall@20: 0.06508474576271187 MRR@20: 0.023324806521715796
2017-11-25 14:23:30,055 - INFO - Epoch: 5 loss: 0.906330 Recall@20: 0.2128813559322034 MRR@20: 0.0776132931658198
2017-11-25 14:26:25,394 - INFO - Epoch: 10 loss: 0.880526 Recall@20: 0.2840677966101695 MRR@20: 0.10107126552235961
2017-11-25 14:29:21,834 - INFO - Epoch: 15 loss: 0.867119 Recall@20: 0.31322033898305085 MRR@20: 0.11081811412424834
2017-11-25 14:32:16,836 - INFO - Epoch: 20 loss: 0.858566 Recall@20: 0.33491525423728813 MRR@20: 0.11434724721210002
2017-11-25 14:35:13,588 - INFO - Epoch: 25 loss: 0.852551 Recall@20: 0.3464406779661017 MRR@20: 0.11801691098078251
2017-11-25 14:38:09,428 - INFO - Epoch: 30 loss: 0.848049 Recall@20: 0.3586440677966102 MRR@20: 0.11944391923108404
2017-11-25 14:41:03,851 - INFO - Epoch: 35 loss: 0.844527 Recall@20: 0.36271186440677966 MRR@20: 0.12174923311516166
2017-11-25 14:43:32,970 - INFO - Epoch: 40 loss: 0.841759 Recall@20: 0.36406779661016947 MRR@20: 0.12507991046635641
2017-11-25 14:46:05,560 - INFO - Epoch: 45 loss: 0.839395 Recall@20: 0.36406779661016947 MRR@20: 0.12604344750361962
2017-11-25 14:48:11,957 - INFO - rnn_size:256  batch_size:128  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.05
2017-11-25 14:48:51,788 - INFO - Epoch: 0 loss: 0.932948 Recall@20: 0.22508474576271187 MRR@20: 0.0825864513475365
2017-11-25 14:51:24,455 - INFO - Epoch: 5 loss: 0.839537 Recall@20: 0.36203389830508476 MRR@20: 0.13049193883026594
2017-11-25 14:53:57,733 - INFO - Epoch: 10 loss: 0.827422 Recall@20: 0.3694915254237288 MRR@20: 0.13924102776527086
2017-11-25 14:56:30,300 - INFO - Epoch: 15 loss: 0.823117 Recall@20: 0.36474576271186443 MRR@20: 0.13223029707111672
2017-11-25 14:59:02,865 - INFO - Epoch: 20 loss: 0.820937 Recall@20: 0.36542372881355933 MRR@20: 0.1304188661967431
2017-11-25 15:01:35,435 - INFO - Epoch: 25 loss: 0.819574 Recall@20: 0.3545762711864407 MRR@20: 0.12499042570601576
2017-11-25 15:04:08,128 - INFO - Epoch: 30 loss: 0.818605 Recall@20: 0.34711864406779663 MRR@20: 0.12694649637675823
2017-11-25 15:06:40,144 - INFO - Epoch: 35 loss: 0.817955 Recall@20: 0.34508474576271186 MRR@20: 0.1255417480463133
2017-11-25 15:09:03,043 - INFO - Epoch: 40 loss: 0.817419 Recall@20: 0.3410169491525424 MRR@20: 0.12810367099914247
2017-11-25 15:11:33,557 - INFO - Epoch: 45 loss: 0.816968 Recall@20: 0.3410169491525424 MRR@20: 0.12800181394055035
2017-11-25 15:13:41,150 - INFO - rnn_size:256  batch_size:256  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.0005
2017-11-25 15:14:15,805 - INFO - Epoch: 0 loss: 0.989728 Recall@20: 0.06779661016949153 MRR@20: 0.023765926589429765
2017-11-25 15:16:17,011 - INFO - Epoch: 5 loss: 0.911866 Recall@20: 0.18847457627118644 MRR@20: 0.07071233286196292
2017-11-25 15:18:17,780 - INFO - Epoch: 10 loss: 0.887361 Recall@20: 0.24677966101694915 MRR@20: 0.09166570120975326
2017-11-25 15:20:18,605 - INFO - Epoch: 15 loss: 0.873660 Recall@20: 0.27728813559322035 MRR@20: 0.0996755471386053
2017-11-25 15:22:18,784 - INFO - Epoch: 20 loss: 0.864257 Recall@20: 0.3023728813559322 MRR@20: 0.10971389697217479
2017-11-25 15:24:19,299 - INFO - Epoch: 25 loss: 0.857380 Recall@20: 0.3111864406779661 MRR@20: 0.11335041420713354
2017-11-25 15:26:20,381 - INFO - Epoch: 30 loss: 0.851952 Recall@20: 0.32745762711864407 MRR@20: 0.11596391639588365
2017-11-25 15:28:21,616 - INFO - Epoch: 35 loss: 0.847581 Recall@20: 0.33559322033898303 MRR@20: 0.12184347517414107
2017-11-25 15:30:21,930 - INFO - Epoch: 40 loss: 0.844000 Recall@20: 0.3410169491525424 MRR@20: 0.12480499211073279
2017-11-25 15:32:21,365 - INFO - Epoch: 45 loss: 0.840985 Recall@20: 0.34915254237288135 MRR@20: 0.12717080120965832
2017-11-25 15:34:01,933 - INFO - rnn_size:256  batch_size:256  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.001
2017-11-25 15:34:36,850 - INFO - Epoch: 0 loss: 0.977400 Recall@20: 0.0928813559322034 MRR@20: 0.031533752109603505
2017-11-25 15:36:38,581 - INFO - Epoch: 5 loss: 0.887969 Recall@20: 0.24 MRR@20: 0.08692096722492379
2017-11-25 15:38:28,653 - INFO - Epoch: 10 loss: 0.865702 Recall@20: 0.29152542372881357 MRR@20: 0.10493022688074374
2017-11-25 15:40:29,218 - INFO - Epoch: 15 loss: 0.853562 Recall@20: 0.32610169491525426 MRR@20: 0.11818500332642118
2017-11-25 15:42:30,491 - INFO - Epoch: 20 loss: 0.845547 Recall@20: 0.3369491525423729 MRR@20: 0.12329646153639963
2017-11-25 15:44:31,100 - INFO - Epoch: 25 loss: 0.839957 Recall@20: 0.34847457627118644 MRR@20: 0.1260783421682304
2017-11-25 15:46:31,837 - INFO - Epoch: 30 loss: 0.835903 Recall@20: 0.3566101694915254 MRR@20: 0.12169170314447644
2017-11-25 15:48:33,318 - INFO - Epoch: 35 loss: 0.832946 Recall@20: 0.3559322033898305 MRR@20: 0.12494401702383023
2017-11-25 15:50:34,719 - INFO - Epoch: 40 loss: 0.830722 Recall@20: 0.3545762711864407 MRR@20: 0.1211052834334568
2017-11-25 15:52:36,469 - INFO - Epoch: 45 loss: 0.828999 Recall@20: 0.3586440677966102 MRR@20: 0.12441259100056393
2017-11-25 15:54:17,532 - INFO - rnn_size:256  batch_size:256  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adam  learning_rate:0.005
2017-11-25 15:54:52,105 - INFO - Epoch: 0 loss: 0.938718 Recall@20: 0.19796610169491524 MRR@20: 0.06446378849267553
2017-11-25 15:56:54,557 - INFO - Epoch: 5 loss: 0.853410 Recall@20: 0.36271186440677966 MRR@20: 0.1306927850358873
2017-11-25 15:58:56,283 - INFO - Epoch: 10 loss: 0.840976 Recall@20: 0.36474576271186443 MRR@20: 0.1221635879964316
2017-11-25 16:00:58,083 - INFO - Epoch: 15 loss: 0.836342 Recall@20: 0.3566101694915254 MRR@20: 0.12934228139727433
2017-11-25 16:02:59,465 - INFO - Epoch: 20 loss: 0.834248 Recall@20: 0.3538983050847458 MRR@20: 0.12470532410806329
2017-11-25 16:04:50,305 - INFO - Epoch: 25 loss: 0.832954 Recall@20: 0.34440677966101696 MRR@20: 0.1256340696030049
2017-11-25 16:06:49,749 - INFO - Epoch: 30 loss: 0.831980 Recall@20: 0.33491525423728813 MRR@20: 0.12305800211577618
2017-11-25 16:08:51,622 - INFO - Epoch: 35 loss: 0.831354 Recall@20: 0.33491525423728813 MRR@20: 0.12483795508975233
2017-11-25 16:10:53,500 - INFO - Epoch: 40 loss: 0.830802 Recall@20: 0.33152542372881355 MRR@20: 0.12062342573962977
2017-11-25 16:12:54,620 - INFO - Epoch: 45 loss: 0.830356 Recall@20: 0.33559322033898303 MRR@20: 0.11861119824185887
2017-11-25 16:14:35,733 - INFO - rnn_size:256  batch_size:256  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.005
2017-11-25 16:15:03,513 - INFO - Epoch: 0 loss: 0.997682 Recall@20: 0.021016949152542375 MRR@20: 0.01036499658533557
2017-11-25 16:16:35,065 - INFO - Epoch: 5 loss: 0.975410 Recall@20: 0.07864406779661016 MRR@20: 0.03276564294998466
2017-11-25 16:18:06,526 - INFO - Epoch: 10 loss: 0.943296 Recall@20: 0.13220338983050847 MRR@20: 0.04836613502232434
2017-11-25 16:19:38,234 - INFO - Epoch: 15 loss: 0.923985 Recall@20: 0.16542372881355932 MRR@20: 0.05817872930681873
2017-11-25 16:21:09,848 - INFO - Epoch: 20 loss: 0.911106 Recall@20: 0.2033898305084746 MRR@20: 0.07114724282090604
2017-11-25 16:22:41,640 - INFO - Epoch: 25 loss: 0.901692 Recall@20: 0.22915254237288135 MRR@20: 0.08049072535738853
2017-11-25 16:24:12,955 - INFO - Epoch: 30 loss: 0.894277 Recall@20: 0.2454237288135593 MRR@20: 0.08782995140918741
2017-11-25 16:25:44,790 - INFO - Epoch: 35 loss: 0.888256 Recall@20: 0.25898305084745765 MRR@20: 0.09464315302568964
2017-11-25 16:27:16,396 - INFO - Epoch: 40 loss: 0.883216 Recall@20: 0.27796610169491526 MRR@20: 0.09979372178432894
2017-11-25 16:28:47,706 - INFO - Epoch: 45 loss: 0.878956 Recall@20: 0.2901694915254237 MRR@20: 0.10230327592506842
2017-11-25 16:30:05,299 - INFO - rnn_size:256  batch_size:256  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.01
2017-11-25 16:30:33,104 - INFO - Epoch: 0 loss: 0.997004 Recall@20: 0.03661016949152542 MRR@20: 0.019449380186668325
2017-11-25 16:32:04,532 - INFO - Epoch: 5 loss: 0.934750 Recall@20: 0.14440677966101695 MRR@20: 0.05449252567993712
2017-11-25 16:33:36,239 - INFO - Epoch: 10 loss: 0.902064 Recall@20: 0.22508474576271187 MRR@20: 0.07874530614185334
2017-11-25 16:34:58,255 - INFO - Epoch: 15 loss: 0.885009 Recall@20: 0.26576271186440675 MRR@20: 0.09929761530674582
2017-11-25 16:36:29,627 - INFO - Epoch: 20 loss: 0.873986 Recall@20: 0.2976271186440678 MRR@20: 0.10993882689931388
2017-11-25 16:38:01,245 - INFO - Epoch: 25 loss: 0.866161 Recall@20: 0.31457627118644066 MRR@20: 0.11319514300628852
2017-11-25 16:39:33,052 - INFO - Epoch: 30 loss: 0.860214 Recall@20: 0.32745762711864407 MRR@20: 0.11682620131846139
2017-11-25 16:41:04,446 - INFO - Epoch: 35 loss: 0.855562 Recall@20: 0.3396610169491525 MRR@20: 0.12119767185115872
2017-11-25 16:42:36,160 - INFO - Epoch: 40 loss: 0.851757 Recall@20: 0.34440677966101696 MRR@20: 0.12107888807943906
2017-11-25 16:44:07,753 - INFO - Epoch: 45 loss: 0.848615 Recall@20: 0.3505084745762712 MRR@20: 0.1224318390500371
2017-11-25 16:45:25,385 - INFO - rnn_size:256  batch_size:256  hidden_act:tanh  dropout_p_hidden:0.5  final_act:tanh  optimizer:adagrad  learning_rate:0.05
2017-11-25 16:45:53,045 - INFO - Epoch: 0 loss: 0.959536 Recall@20: 0.1423728813559322 MRR@20: 0.046594386472121684
2017-11-25 16:47:24,612 - INFO - Epoch: 5 loss: 0.854966 Recall@20: 0.32677966101694916 MRR@20: 0.12229807608796955
2017-11-25 16:48:56,403 - INFO - Epoch: 10 loss: 0.836032 Recall@20: 0.34983050847457625 MRR@20: 0.1309450430569704
2017-11-25 16:50:28,469 - INFO - Epoch: 15 loss: 0.828655 Recall@20: 0.3572881355932203 MRR@20: 0.13357887612728353
2017-11-25 16:51:59,405 - INFO - Epoch: 20 loss: 0.825012 Recall@20: 0.3538983050847458 MRR@20: 0.13589284565521642
2017-11-25 16:53:30,846 - INFO - Epoch: 25 loss: 0.822958 Recall@20: 0.3566101694915254 MRR@20: 0.1335202278262571
2017-11-25 16:55:02,409 - INFO - Epoch: 30 loss: 0.821564 Recall@20: 0.35322033898305083 MRR@20: 0.1319211701727575
2017-11-25 16:56:33,794 - INFO - Epoch: 35 loss: 0.820603 Recall@20: 0.3552542372881356 MRR@20: 0.12993680800725455
2017-11-25 16:58:04,655 - INFO - Epoch: 40 loss: 0.819830 Recall@20: 0.351864406779661 MRR@20: 0.12918446987993612
2017-11-25 16:59:35,944 - INFO - Epoch: 45 loss: 0.819236 Recall@20: 0.351864406779661 MRR@20: 0.12609948406353927
